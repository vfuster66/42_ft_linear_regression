# ğŸ“Š FT_LINEAR_REGRESSION  
## ImplÃ©mentation d'une rÃ©gression linÃ©aire simple

---

## ğŸ“Œ Objectif du projet  
Ce projet implÃ©mente un modÃ¨le de **rÃ©gression linÃ©aire simple** afin de **prÃ©dire le prix d'un vÃ©hicule en fonction de son kilomÃ©trage**.  
L'objectif est de mettre en pratique les **fondamentaux du machine learning**, Ã  travers l'implÃ©mentation de **la descente de gradient**, sans utiliser de bibliothÃ¨ques spÃ©cialisÃ©es dans la rÃ©gression.

L'algorithme ajuste les paramÃ¨tres **Î¸â‚€** et **Î¸â‚** pour minimiser la fonction de coÃ»t **J(Î¸)**, permettant ainsi d'obtenir des **prÃ©dictions prÃ©cises**.

---

## ğŸ“š Qu'est-ce que la rÃ©gression linÃ©aire simple ?

La **rÃ©gression linÃ©aire simple** est une mÃ©thode statistique qui permet de modÃ©liser la relation entre deux variables :
- **Une variable indÃ©pendante (feature)** â” ici le **kilomÃ©trage**
- **Une variable dÃ©pendante (target)** â” ici le **prix de la voiture**

Elle cherche Ã  ajuster une droite (appelÃ©e **droite de rÃ©gression**) qui prÃ©dit au mieux la valeur de la variable dÃ©pendante en fonction de la variable indÃ©pendante. Cette droite est dÃ©finie par l'Ã©quation :

```
estimatePrice(mileage) = Î¸â‚€ + (Î¸â‚ * mileage)
```

- **Î¸â‚€ (theta zero)** est l'ordonnÃ©e Ã  l'origine â” c'est la valeur prÃ©dite lorsque le kilomÃ©trage est nul.
- **Î¸â‚ (theta un)** est la pente â” il dÃ©termine comment le prix Ã©volue avec le kilomÃ©trage.

L'objectif est de trouver les meilleurs **Î¸â‚€** et **Î¸â‚** qui minimisent l'erreur entre les valeurs prÃ©dites et les valeurs rÃ©elles. Cette erreur est mesurÃ©e via la **fonction de coÃ»t J(Î¸)**, gÃ©nÃ©ralement l'**erreur quadratique moyenne** (**Mean Squared Error - MSE**).

### âœï¸ Pour aller plus loin :
- [RÃ©gression LinÃ©aire Simple - WikipÃ©dia](https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire)
- [Linear Regression Explained - Towards Data Science](https://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86)
- [Gradient Descent Algorithm - GeeksforGeeks](https://www.geeksforgeeks.org/gradient-descent-in-linear-regression/)
- [Machine Learning Crash Course - Google](https://developers.google.com/machine-learning/crash-course)

---

## âš™ï¸ FonctionnalitÃ©s principales

âœ… **EntraÃ®nement du modÃ¨le par descente de gradient**  
âœ… **Sauvegarde et chargement des paramÃ¨tres (Î¸â‚€, Î¸â‚) en JSON**  
âœ… **Normalisation / DÃ©normalisation des donnÃ©es d'entrÃ©e et de sortie**  
âœ… **Gestion complÃ¨te des erreurs et contrÃ´le des limites de prÃ©diction**  
âœ… **PrÃ©dictions en temps rÃ©el ou en batch sur de nouveaux kilomÃ©trages**

---

## ğŸ§  Concepts abordÃ©s

- RÃ©gression linÃ©aire simple  
- Fonction de coÃ»t **J(Î¸)** (Erreur quadratique moyenne)  
- Optimisation par **descente de gradient**  
- Normalisation des donnÃ©es pour amÃ©liorer la convergence  
- Ã‰valuation des performances (MSE et RÂ²)

---

## âœ¨ Bonus implÃ©mentÃ©s

| Bonus | Description |
|-------|-------------|
| âœ… Sauvegarde et chargement du modÃ¨le en **JSON** | Facilite la lecture et la rÃ©utilisation des paramÃ¨tres Î¸â‚€, Î¸â‚ et des valeurs de normalisation |
| âœ… **Visualisation de la droite de rÃ©gression** | Graphique `regression_plot.png` superposant la droite de rÃ©gression aux donnÃ©es initiales |
| âœ… **Courbe de coÃ»t J(Î¸)** | Graphique `cost_function_plot.png` affichant l'Ã©volution du coÃ»t durant l'entraÃ®nement |
| âœ… **Graphique des rÃ©sidus** | `residuals_plot.png` visualise la diffÃ©rence entre valeurs prÃ©dites et rÃ©elles |
| âœ… **Histogramme des erreurs de prÃ©diction** | `error_distribution.png` montrant la rÃ©partition des erreurs |
| âœ… **Boxplot de la distribution initiale des donnÃ©es** | `data_distribution.png` pour visualiser la dispersion des valeurs |
| âœ… **Histogramme de la rÃ©partition du kilomÃ©trage** | `mileage_distribution.png` |
| âœ… **Comparaison graphique entre MSE et RÂ²** | `metrics_comparison.png` comparant les performances du modÃ¨le |
| âœ… **PrÃ©dictions en batch avec extrapolation modÃ©rÃ©e (Â±20%)** | Limite la prÃ©diction Ã  des valeurs rÃ©alistes et contrÃ´lÃ©es |
| âœ… **Sauvegarde rÃ©guliÃ¨re des checkpoints pendant l'entraÃ®nement** | Fichiers `model_epoch_{epoch}.json` pour reprendre ou analyser la progression |
| âœ… **Calcul du coefficient RÂ²** | Fournit une mÃ©trique alternative et complÃ©mentaire au MSE |
| âœ… **Gestion robuste des erreurs** | ContrÃ´le des entrÃ©es utilisateur, vÃ©rification des fichiers, gestion des prÃ©dictions hors limites |

---

## ğŸš€ Visualisation des rÃ©sultats graphiques

Les graphiques gÃ©nÃ©rÃ©s sont automatiquement **sauvegardÃ©s** dans le rÃ©pertoire `app/` ou le rÃ©pertoire courant selon la configuration Docker.  
### ğŸ“‚ Liste des graphiques :
- `regression_plot.png` â” DonnÃ©es initiales et droite de rÃ©gression  
- `cost_function_plot.png` â” Courbe de coÃ»t J(Î¸)  
- `residuals_plot.png` â” Graphique des rÃ©sidus  
- `error_distribution.png` â” Histogramme des erreurs de prÃ©diction  
- `data_distribution.png` â” Boxplot des distributions kilomÃ©trage / prix  
- `mileage_distribution.png` â” Histogramme des kilomÃ©trages  
- `metrics_comparison.png` â” Comparaison directe MSE / RÂ²  

---

## ğŸ“Œ PrÃ©dictions rÃ©alistes et contrÃ´lÃ©es

Le modÃ¨le **prÃ©vient les extrapolations extrÃªmes** :  
- Les prÃ©dictions sont limitÃ©es Ã  une **plage de confiance** basÃ©e sur le dataset dâ€™origine (+/- 20%).  
- Si l'utilisateur saisit un kilomÃ©trage en dehors de ces bornes, un **message clair** est retournÃ©, indiquant les limites valides.

---

## ğŸ“ˆ MÃ©triques de performance

Les performances du modÃ¨le sont mesurÃ©es Ã  lâ€™aide des indicateurs suivants :  
| **MÃ©trique**        | **Valeur**        |
|---------------------|-------------------|
| **MSE (Mean Squared Error)** | `445645.25` |
| **RÂ² (Coefficient de dÃ©termination)** | `0.7330` â” Le modÃ¨le explique **73 %** de la variance |

Ces mÃ©triques sont affichÃ©es lors de l'exÃ©cution de `evaluate.py` et visualisÃ©es dans `metrics_comparison.png`.

---

## ğŸ› ï¸ Commandes rapides

Le projet est entiÃ¨rement **dockerisÃ©** pour une exÃ©cution simple et reproductible.

```bash
make build      # Construire l'image Docker
make train      # EntraÃ®ner le modÃ¨le (lance train.py)
make predict    # Faire une prÃ©diction (lance predict.py)
make evaluate   # Ã‰valuer le modÃ¨le et gÃ©nÃ©rer les graphiques bonus (lance evaluate.py)
make test       # Lancer les tests unitaires
make clean      # Supprimer les ressources Docker inutilisÃ©es
make purge      # Supprimer complÃ¨tement l'image Docker
```

---

## âš™ï¸ Structure des fichiers
```
.
â”œâ”€â”€ data.csv                      # Dataset utilisÃ© pour l'entraÃ®nement
â”œâ”€â”€ train.py                      # EntraÃ®nement du modÃ¨le par descente de gradient
â”œâ”€â”€ predict.py                    # PrÃ©diction du prix d'un vÃ©hicule Ã  partir du kilomÃ©trage
â”œâ”€â”€ evaluate.py                   # Ã‰valuation du modÃ¨le (MSE, RÂ²) et gÃ©nÃ©ration des graphiques
â”œâ”€â”€ model.json                    # Sauvegarde des paramÃ¨tres Î¸ et des normalisations
â”œâ”€â”€ regression_plot.png           # Graphique de la droite de rÃ©gression
â”œâ”€â”€ cost_function_plot.png        # Courbe de coÃ»t J(Î¸)
â”œâ”€â”€ residuals_plot.png            # Graphique des rÃ©sidus
â”œâ”€â”€ mileage_distribution.png      # Histogramme du kilomÃ©trage
â”œâ”€â”€ data_distribution.png         # Boxplot des donnÃ©es
â”œâ”€â”€ error_distribution.png        # Histogramme des erreurs
â”œâ”€â”€ metrics_comparison.png        # Comparaison MSE / RÂ²
â”œâ”€â”€ Dockerfile                    # Dockerfile pour l'environnement d'exÃ©cution
â”œâ”€â”€ Makefile                      # Automatisation des commandes courantes
â””â”€â”€ requirements.txt              # DÃ©pendances Python (numpy, matplotlib, etc.)
```

---

## ğŸ¯ Conclusion

Ce projet **FT_LINEAR_REGRESSION** propose une **expÃ©rience complÃ¨te et didactique** sur les concepts fondamentaux de la **rÃ©gression linÃ©aire** et de la **descente de gradient**, enrichie par des **visualisations**, des **mÃ©triques dÃ©taillÃ©es** et une **gestion robuste des donnÃ©es**.  

GrÃ¢ce Ã  une **interface utilisateur simple** et une **dockerisation complÃ¨te**, il permet de **visualiser facilement** les performances du modÃ¨le, tout en respectant les contraintes pÃ©dagogiques du sujet **42**.

---
