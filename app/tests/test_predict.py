import sys
import os
from colorama import Fore, Style, init
from predict import load_model, batch_predict

sys.path.insert(
    0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
)

init(autoreset=True)


def test_load_model():
    """ğŸ“‚ Test du chargement du modÃ¨le."""
    print(f"{Fore.YELLOW}ğŸ“‚ Test: Chargement du modÃ¨le...{Style.RESET_ALL}")
    model = load_model("model.json")
    assert "theta0" in model, "âŒ Le modÃ¨le doit contenir Î¸0"
    assert "theta1" in model, "âŒ Le modÃ¨le doit contenir Î¸1"
    print(f"{Fore.GREEN}âœ… ModÃ¨le chargÃ© avec succÃ¨s !{Style.RESET_ALL}")


def test_batch_predict_limits():
    """âš ï¸ Test: VÃ©rification des limites batch."""
    model = load_model()
    theta0, theta1 = model["theta0"], model["theta1"]

    valid_mileages = [5000, 150000, 250000]
    invalid_mileages = [-100, 350000]

    predictions_valid = batch_predict(valid_mileages, theta0, theta1)
    assert predictions_valid is not None, \
        "âŒ Batch valide ne doit pas retourner None"
    assert len(predictions_valid) == len(valid_mileages), \
        "âŒ Mauvais nombre de prÃ©dictions retournÃ©es"

    predictions_invalid = batch_predict(invalid_mileages, theta0, theta1)
    assert predictions_invalid is None, "âŒ Batch invalide doit retourner None"

    print(f"{Fore.GREEN}âœ… Limites des prÃ©dictions batch validÃ©es !"
          f"{Style.RESET_ALL}")
